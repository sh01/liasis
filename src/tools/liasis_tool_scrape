#!/usr/bin/env python
#Copyright 2007 Sebastian Hagen
# This file is part of liasis.
#
# liasis is free software; you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 2 of the License, or
# (at your option) any later version.
#
# liasis is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.

import sys
import optparse
import urllib.request
import gzip
from io import BytesIO

from liasis.benc_structures import BTMetaInfo, py_from_benc_str

if (__name__ == '__main__'):
   op = optparse.OptionParser()
   op.add_option('-t', '--tier', dest='tier', type='long', default=0, help='tier from which to use tracker')
   op.add_option('-i', '--index', dest='index', type='long', default=0, help='index of tracker to use inside tier')
   op.add_option('-f', '--full', dest='info_hash_send', action='store_false', default=True, help="do not send 'info_hash' parameter to tracker; retrieve information for all tracked torrents")

   (options, args) = op.parse_args()
   
   tf_name = args[0]
   mi = BTMetaInfo.build_from_benc_stream(open(tf_name,'rb'), announce_urls_shuffle=False)
   info_hash = mi.info_hash
   for i in range(len(mi.announce_urls)):
      print('Trackers in tier {0}: {1}'.format(i, ' '.join([ascii(url) for url in mi.announce_urls[i]])))
   
   tracker_url = mi.announce_urls[options.tier][options.index]
   print('using tracker_url {0!a}...'.format(tracker_url))
   
   tracker_url_split = tracker_url.split(b'/')
   
   if not (tracker_url_split[-1].startswith(b'announce')):
      sys.exit()
   
   tracker_url_split[-1] = b'scrape' + tracker_url_split[-1][8:]

   tracker_url_scrape = b'/'.join(tracker_url_split)
   
   if (options.info_hash_send):
      tracker_url_scrape += b'?info_hash=' + urllib.request.quote(info_hash).encode('ascii')
   
   print('scrape url: {0!a}'.format(tracker_url_scrape))
   print(b'Fetching and parsing...')
   scrape_urlo = urllib.request.urlopen(tracker_url_scrape.decode('ascii'))
   scrape_str = scrape_urlo.read()
   if ('Content-Encoding' in scrape_urlo.headers):
      content_encoding = scrape_urlo.headers['Content-Encoding']
      print('Content-Encoding is {0!a}.'.format(content_encoding))
      if (content_encoding == 'gzip'):
         print('Ungzipping data.')
         scrape_str = gzip.GzipFile(fileobj=BytesIO(scrape_str)).read()
   
   scrape_data = py_from_benc_str(scrape_str)

   file_data = scrape_data[b'files']
   
   
   print('Fetched scrape data for {0} files.'.format(len(file_data)))
   
   torrent_data = file_data[info_hash]
   print('Data specific to torrent {0!a}:'.format(info_hash))
   
   print(torrent_data)

